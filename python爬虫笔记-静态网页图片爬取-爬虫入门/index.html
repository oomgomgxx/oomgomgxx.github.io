<!DOCTYPE html>
<html lang="zh-CN">

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="keywords" content="" />
  <meta name="author" content="DeeTam" />
  <meta name="description" content="学然后知不足" />
  
  
  <title>
    
      Python爬虫笔记-入门 
      
      
    
  </title>

  
    <link rel="apple-touch-icon" href="/images/favicon.png">
    <link rel="icon" href="/images/favicon.png">
  

  <!-- Raleway-Font -->
  <link href="https://fonts.googleapis.com/css?family=Montserrat|Roboto:400,400italic,600|Roboto+Mono" rel="stylesheet">

  <!-- hexo site css -->
  
<link rel="stylesheet" href="/css/base.css">
<link rel="stylesheet" href="/css/common.css">
<link rel="stylesheet" href="/iconfont/iconfont.css">


  

  
    
<link rel="stylesheet" href="/css/post.css">

  

  <!-- jquery3.3.1 -->
  <script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>

  <!-- fancybox -->
  <link href="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.css" rel="stylesheet">
  <script async src="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.js"></script>
  
<script src="/js/fancybox.js"></script>


<meta name="generator" content="Hexo 6.3.0"></head>


  <body>
    <div id="app">
      <div class="header">
  <a href="/">DEE TAM</a>
</div>


      <p class="links">
  
    <a title="归档" target="" href="/archives/">
      <i class="iconfont icon-bookmark"></i>
    </a>
  
    <a title="邮箱" target="" href="mailto:oomgomgxx@gmail.com">
      <i class="iconfont icon-envelope"></i>
    </a>
  
    <a title="QQ" target="" href="tencent://message/?Menu=yes&uin=0x1DACE601&Service=300&sigT=45a1e5847943b64c6ff3990f8a9e644d2b31356cb0b4ac6b24663a3c8dd0f8aa12a595b1714f9d45">
      <i class="iconfont icon-qq"></i>
    </a>
  
    <a title="关于" target="" href="/about/">
      <i class="iconfont icon-emoji-friendly"></i>
    </a>
  
</p>


      <div class="main">
        <!-- 文章详情页，展示文章具体内容，url形式：https://yoursite/文章标题/ -->
<!-- 同时为「标签tag」，「朋友friend」，「分类categories」，「关于about」页面的承载页面，具体展示取决于page.type -->

<!-- LaTex Display -->
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>

<div class="post">
  
  <!--
  
    <h3 class="date">
    Mar 13, 2018
  </h3>
  
  -->

  
  <center>
    <h1>
      Python爬虫笔记-入门
    </h1>
  </center>
  

  <div class="content markdown-body">
    <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># =========== requests基本使用 ===========</span></span><br><span class="line"><span class="comment"># 安装requests模块：用于请求(访问)网站</span></span><br><span class="line"><span class="comment"># pip install requests</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求网站（指定爬取目标）</span></span><br><span class="line"><span class="comment"># response = requests.get(&#x27;https://news.163.com&#x27;)</span></span><br><span class="line"><span class="comment"># 获取返回的文本内容</span></span><br><span class="line"><span class="comment"># text = response.text</span></span><br><span class="line"><span class="comment"># print(text)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># =========== 使用BeautifulSoup获取页面标签 ===========</span></span><br><span class="line"><span class="comment"># 安装beautifulsoup4模块：用于解析requests返回的文本内容</span></span><br><span class="line"><span class="comment"># pip install beautifulsoup4</span></span><br><span class="line"><span class="comment"># 安装lxml解析器</span></span><br><span class="line"><span class="comment"># 1.</span></span><br><span class="line"><span class="comment">#  http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml</span></span><br><span class="line"><span class="comment">#  下载适合自己python版本的whl文件，如下为我下载的版本</span></span><br><span class="line"><span class="comment"># 2. 切换到下载whl文件所在目录安装whl，如下</span></span><br><span class="line"><span class="comment"># pip3 install lxml-4.3.3-cp37-cp37m-win_amd64.whl</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># response = requests.get(&#x27;https://news.163.com&#x27;)</span></span><br><span class="line"><span class="comment"># text = response.text</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定BeautifulSoup使用lxml解析文本内容</span></span><br><span class="line"><span class="comment"># soup = BeautifulSoup(text, &#x27;lxml&#x27;)</span></span><br><span class="line"><span class="comment"># 使用find方法查到第一个img标签</span></span><br><span class="line"><span class="comment"># find = soup.find(&#x27;img&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出返回值类型</span></span><br><span class="line"><span class="comment"># print(&quot;find的类型：&quot;, type(find))</span></span><br><span class="line"><span class="comment"># 输出find获取的值</span></span><br><span class="line"><span class="comment"># print(&quot;整合标签定义：&quot;, find)</span></span><br><span class="line"><span class="comment"># 输出标签的名字</span></span><br><span class="line"><span class="comment"># print(&quot;标签名称：&quot;, find.name)</span></span><br><span class="line"><span class="comment"># 输出标签的_src属性值</span></span><br><span class="line"><span class="comment"># print(&quot;图片：&quot;, find[&#x27;src&#x27;])</span></span><br><span class="line"><span class="comment"># 标签体内容</span></span><br><span class="line"><span class="comment"># print(&#x27;标签体内容：&#x27;, find.string)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># =========== 获取html注释内容 ===========</span></span><br><span class="line"><span class="comment"># markup = &quot;&lt;b&gt;&lt;!-- python爬虫学习 --&gt;&lt;/b&gt;&lt;a href=&#x27;www.bing.com&#x27;&gt;&lt;!-- aaa python爬虫学习 --&gt;&lt;/a&gt;&quot;</span></span><br><span class="line"><span class="comment"># soup = BeautifulSoup(markup, &#x27;lxml&#x27;)</span></span><br><span class="line"><span class="comment"># print(&#x27;b注释内容：&#x27;, soup.b.string)</span></span><br><span class="line"><span class="comment"># print(&#x27;a注释内容：&#x27;, soup.a.string)</span></span><br><span class="line"><span class="comment"># 查找标签string表达式：soup.标签名称.string</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># =========== 遍历img标签(强大的find_all方法) ===========</span></span><br><span class="line"><span class="comment"># response = requests.get(&#x27;https://news.163.com&#x27;)</span></span><br><span class="line"><span class="comment"># text = response.text</span></span><br><span class="line"><span class="comment"># soup = BeautifulSoup(text, &#x27;lxml&#x27;)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># #得到所有的&lt;a&gt;标签</span></span><br><span class="line"><span class="comment"># find_all = soup.find_all(&#x27;img&#x27;)</span></span><br><span class="line"><span class="comment"># for img in find_all:</span></span><br><span class="line"><span class="comment">#     # print(type(img))</span></span><br><span class="line"><span class="comment">#     # &lt;class &#x27;bs4.element.Tag&#x27;&gt;</span></span><br><span class="line"><span class="comment">#     if img.get(&#x27;src&#x27;):</span></span><br><span class="line"><span class="comment">#         print(img.get(&#x27;src&#x27;))</span></span><br><span class="line"><span class="comment">#     else:</span></span><br><span class="line"><span class="comment">#         print(img.get(&#x27;data-src&#x27;))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># =========== 图片保存相关 ===========</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">dirName = <span class="string">&#x27;C:/Users/admin/Desktop/py_save&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建文件夹</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mkdir</span>(<span class="params">path</span>):</span><br><span class="line">    path = path.strip()</span><br><span class="line">    isExists = os.path.exists(path)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isExists:</span><br><span class="line">        os.makedirs(path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;文件夹创建成功&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(path, <span class="string">&#x27;文件夹已经存在了，不再创建&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建文件夹</span></span><br><span class="line">mkdir(dirName)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存图片</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">saveImg</span>(<span class="params">requests, url, dirName, fileName</span>):</span><br><span class="line">    img = requests.get(url)</span><br><span class="line">    file_name = dirName + <span class="string">&#x27;/&#x27;</span> + fileName + <span class="string">&#x27;.png&#x27;</span></span><br><span class="line">    f = <span class="built_in">open</span>(file_name, <span class="string">&#x27;ab&#x27;</span>)</span><br><span class="line">    f.write(img.content)</span><br><span class="line">    <span class="built_in">print</span>(file_name, <span class="string">&#x27;文件保存成功！&#x27;</span>)</span><br><span class="line">    f.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># =========== 去除https://unsplash.com/t/wallpapers中图片地址后面的参数 ===========</span></span><br><span class="line"></span><br><span class="line">reqUrl = <span class="string">&#x27;https://unsplash.com/t/wallpapers&#x27;</span></span><br><span class="line">text = requests.get(reqUrl).text</span><br><span class="line">soup = BeautifulSoup(text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> uuid</span><br><span class="line"></span><br><span class="line"><span class="comment">#得到所有的&lt;a&gt;标签</span></span><br><span class="line">find_all = soup.find_all(<span class="string">&#x27;img&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> img <span class="keyword">in</span> find_all:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 文件名称</span></span><br><span class="line">    uuid_ = uuid.uuid1()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> img.get(<span class="string">&#x27;src&#x27;</span>):</span><br><span class="line">        <span class="comment"># 将后面的参数去掉，即?后面的内容</span></span><br><span class="line">        url = img.get(<span class="string">&#x27;src&#x27;</span>).split(<span class="string">&#x27;?&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        saveImg(requests, url, dirName, <span class="built_in">str</span>(uuid_))</span><br></pre></td></tr></table></figure>


  </div>
  
    
      <a id="older" class="blog-nav" href="/%E4%BB%8EConcurrentModificationException%E5%88%86%E6%9E%90ArrayList%E8%BF%AD%E4%BB%A3%E5%99%A8/">OLDER&nbsp;&gt;</a>
      
        
          <a id="newer" class="blog-nav" href="/%E5%85%B3%E4%BA%8EThreadLocal%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E5%92%8CThreadLocalMap%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90/">&lt;&nbsp;NEWER</a>
          
            
</div>
        <div class="footer">
  
    <div class="footer-more">
      
        <a href="/"><em style="color:red;">新站点正在开发中，网站暂停更新。</em></a>
        
    </div>
  
    <div class="footer-more">
      
        <a href="/">Copyright © DeeTam 2022</a>
        
    </div>
  
</div>

      </div>

      <div class="back-to-top hidden">
  <a href="javascript: void(0)">
    <i class="iconfont icon-chevronup"></i>
  </a>
</div>


<script src="/js/backtotop.js"></script>



      
  <div class="search-icon" id="search-icon">
    <a href="javascript: void(0)">
      <i class="iconfont icon-search"></i>
    </a>
  </div>

  <div class="search-overlay hidden">
    <div class="search-content" tabindex="0">
      <div class="search-box">
        <div class="search-title">
          <!-- <span class="search-icon-input">
            <a href="javascript: void(0)">
              <i class="iconfont icon-search"></i>
            </a>
          </span> -->
          
            <input type="text" class="search-input" id="search-input" placeholder="搜索...">
          
          <span class="search-close-icon" id="search-close-icon">
            <a href="javascript: void(0)">
              <i class="iconfont icon-close"></i>
            </a>
          </span>
        </div>
        <div class="search-result" id="search-result"></div>
      </div>
    </div>
  </div>

  <script type="text/javascript">
    var inputArea = document.querySelector("#search-input")
    var searchOverlayArea = document.querySelector(".search-overlay")

    // inputArea.onclick = function() {
    //   getSearchFile()
    //   this.onclick = null
    // }

    inputArea.onkeydown = function() {
      if(event.keyCode == 13)
        return false
    }

    function openOrHideSearchContent() {
      let isHidden = searchOverlayArea.classList.contains('hidden')
      if (isHidden) {
        searchOverlayArea.classList.remove('hidden')
        document.body.classList.add('hidden')
        inputArea.focus()
        getSearchFile()
      } else {
        searchOverlayArea.classList.add('hidden')
        document.body.classList.remove('hidden')
      }
    }

    function blurSearchContent(e) {
      if (e.target === searchOverlayArea) {
        openOrHideSearchContent()
      }
    }

    document.querySelector("#search-icon").addEventListener("click", openOrHideSearchContent, false)
    document.querySelector("#search-close-icon").addEventListener("click", openOrHideSearchContent, false)
    searchOverlayArea.addEventListener("click", blurSearchContent, false)

    var searchFunc = function (path, search_id, content_id) {
      'use strict';
      var $input = document.getElementById(search_id);
      var $resultContent = document.getElementById(content_id);
      $resultContent.innerHTML = "<ul><span class='local-search-empty'><span></ul>";
      // $resultContent.innerHTML = "<ul><span class='local-search-empty'>首次搜索，正在载入索引文件，请稍后……<span></ul>";
      $.ajax({
        // 0x01. load xml file
        url: path,
        dataType: "xml",
        success: function (xmlResponse) {
          // 0x02. parse xml file
          var datas = $("entry", xmlResponse).map(function () {
            return {
              title: $("title", this).text(),
              content: $("content", this).text(),
              url: $("url", this).text()
            };
          }).get();
          $resultContent.innerHTML = "";

          $input.addEventListener('input', function () {
            // 0x03. parse query to keywords list
            var str = '<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length <= 0) {
              return;
            }
            // 0x04. perform local searching
            datas.forEach(function (data) {
              var isMatch = true;
              var content_index = [];
              if (!data.title || data.title.trim() === '') {
                data.title = "Untitled";
              }
              var orig_data_title = data.title.trim();
              var data_title = orig_data_title.toLowerCase();
              var orig_data_content = data.content.trim().replace(/<[^>]+>/g, "");
              var data_content = orig_data_content.toLowerCase();
              var data_url = data.url;
              var index_title = -1;
              var index_content = -1;
              var first_occur = -1;
              // only match artiles with not empty contents
              if (data_content !== '') {
                keywords.forEach(function (keyword, i) {
                  index_title = data_title.indexOf(keyword);
                  index_content = data_content.indexOf(keyword);

                  if (index_title < 0 && index_content < 0) {
                    isMatch = false;
                  } else {
                    if (index_content < 0) {
                      index_content = 0;
                    }
                    if (i == 0) {
                      first_occur = index_content;
                    }
                    // content_index.push({index_content:index_content, keyword_len:keyword_len});
                  }
                });
              } else {
                isMatch = false;
              }
              // 0x05. show search results
              if (isMatch) {
                str += "<li><a href='/" + data_url + "' class='search-result-title'><h2>" + orig_data_title + "</h2></a>";
                var content = orig_data_content;
                if (first_occur >= 0) {
                  // cut out 100 characters
                  var start = first_occur - 20;
                  var end = first_occur + 80;

                  if (start < 0) {
                    start = 0;
                  }

                  if (start == 0) {
                    end = 100;
                  }

                  if (end > content.length) {
                    end = content.length;
                  }

                  var match_content = content.substr(start, end);

                  // highlight all keywords
                  keywords.forEach(function (keyword) {
                    var regS = new RegExp(keyword, "gi");
                    match_content = match_content.replace(regS, "<span class=\"search-keyword\">" + keyword + "</span>");
                  });

                  str += "<h3 class=\"search-result-abstract\">" + match_content + "...</h3>"
                }
                str += "<hr></li>";
              }
            });
            str += "</ul>";
            if (str.indexOf('<li>') === -1) {
              return $resultContent.innerHTML = "<ul><span class='local-search-empty'>没有找到内容，请尝试更换检索词。<span></ul>";
            }
            $resultContent.innerHTML = str;
          });
        },
        error: function(xhr, status, error) {
          $resultContent.innerHTML = ""
          if (xhr.status === 404) {
            $resultContent.innerHTML = "<ul><span class='local-search-empty'>未找到search.xml文件，具体请参考：<a href='https://github.com/leedom92/hexo-theme-leedom#configuration' target='_black'>configuration</a><span></ul>";
          } else {
            $resultContent.innerHTML = "<ul><span class='local-search-empty'>请求失败，尝试重新刷新页面或稍后重试。<span></ul>";
          }
        }
      });
      $(document).on('click', '#search-close-icon', function() {
        $('#search-input').val('');
        $('#search-result').html('');
      });
    }

    var getSearchFile = function() {
        var path = "/search.xml";
        searchFunc(path, 'search-input', 'search-result');
    }
  </script>




    </div>
  </body>
</html>
